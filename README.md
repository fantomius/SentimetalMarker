# SentimetalMarker
Приложение, различающее эмоциональную окраску предложений

# Решение 
Просмотрев несколько источников я нашел два возможных подхода к этой задачи: 
1) Разбиение предложения на слова, оценки слов по отдельности и выставление итоговой оценки на их основе 
2) Обучение по корпусу размеченных текстов и определение близости переданного предложения к тому или иному эталону

Так как никакого размеченного корпуса предложений я не нашел, то было принятно решение использовать 1-ый подход. 
Определять окраску слова можно так-же двумя способами: 
1) Можно оценивать слова по размеченному корпусу (вероятность, что предложение положительное, если в нём встретилось такое слово) 
2) Можно использовать имеющиеся размеченные словари 

Я остановился на 2-м подходе. Возможно стоит добавить ещё и 1-ый, но он имеет ряд "НО": 
а) Оценка вероятностей сильно зависит от корпуса. Соответсвенно, если итоговые предложения будут отличаться от тех, на которых мы учились, то мы получим неверные результаты 
б) Нужен достаточно большой корпус 

После того, как я принял решение использовать 2-ой подход я занялся поиском словарей. К сожалению, для русского языка, всё не так радужно как для английского. Я нашел 3 разных словаря с разными шкалами оценок: 
1) https://github.com/Wobot/Sentimental 
2) http://lilu.fcim.utm.md/resourcesRoRuWNA.html 
3) http://linis-crowd.org/ 

В 3-м варианте был ещё и корпус размеченных текстов 

Так как все эти словари не очень большие, то я принял решение использовать их все. Оставалось дело за малым - построить готовое решение 

Изначально была сделана загрузка этих словарей + вовзращение оценки для каждого слова по ним (см. dictionaries.py) 
Далее был написан SentimentalEstimator( sentimental_estimator.py ), который разбивает предложение на слова, оценивает их по всем словарям в отдельности, и возвращает результат 
Результат определяется по очень простой формуле если abs( pos - negative ) < neutral_treshold, то результат - нейтральный, иначе возвращаем pos или negative 

Разбиение предложения на слова происходит так: 
а) Сначала мы удаляем из предложения пунктуацию и цифры 
б) Затем мы разбиваем его на слова 
в) И наконец приводим каждое слово в начальную форму (для существительных это - ед.ч., м.р., и.п.) 

Возникла потребность в оценке полученной машины. Для этого был написан класс TextsCorpus(textscorpus.py) и вспомогательная функция (get_sentences_quality), которые прогоняли алгоритм по базе из linis-crowd и писали количество правильно классифицированных ответов 

Сразу же встал вопрос как правильно настроить веса каждого словаря и neutral_treshold. Для этого я воспользовался дифф эволюцией (её можно найти в corpus_evolution.py). Я согласен, что оценивать и настраивать машинку на корпусе длинных текстов, а не отдельных предложений задача немного другая. Впрочем, я думаю, что это всё-таки улучшит результаты. 

Ну и наконец был написан некий GUI на qt4, который даёт возможность всё это поприменять и посмотреть как оно работает 

Дальнейшее улучшение: 
а) Собрать корпус предложений 
б) Добавить оценку вероятности того, что каждое слово позитивное или негативное, на основе этого корпуса 
в) Соединить это с текущим подходом с оценкой по словарю
г) Разные функции отнесения к тому или иному классу. Например, сначала отделять нейтральные, а затем уже делить на позитивные и негативные