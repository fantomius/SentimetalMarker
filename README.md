# SentimetalMarker
Приложение, различающее эмоциональную окраску предложений

# Решение 
Просмотрев несколько источников я нашел два возможных подхода к этой задачи:<br/>
1) Разбиение предложения на слова, оценки слов по отдельности и выставление итоговой оценки на их основе <br/>
2) Обучение по корпусу размеченных текстов и определение близости переданного предложения к тому или иному эталону<br/>
<br/>
Так как никакого размеченного корпуса предложений я не нашел, то было принятно решение использовать 1-ый подход. <br/>
Определять окраску слова можно так-же двумя способами: <br/>
1) Можно оценивать слова по размеченному корпусу (вероятность, что предложение положительное, если в нём встретилось такое слово) <br/>
2) Можно использовать имеющиеся размеченные словари <br/>
<br/>
Я остановился на 2-м подходе. Возможно стоит добавить ещё и 1-ый, но он имеет ряд "НО": <br/>
а) Оценка вероятностей сильно зависит от корпуса. Соответсвенно, если итоговые предложения будут отличаться от тех, на которых мы учились, то мы получим неверные результаты <br/>
б) Нужен достаточно большой корпус <br/>
<br/>
После того, как я принял решение использовать 2-ой подход я занялся поиском словарей. К сожалению, для русского языка, всё не так радужно как для английского. Я нашел 3 разных словаря с разными шкалами оценок: <br/>
1) https://github.com/Wobot/Sentimental <br/>
2) http://lilu.fcim.utm.md/resourcesRoRuWNA.html <br/>
3) http://linis-crowd.org/ <br/>
<br/>
В 3-м варианте был ещё и корпус размеченных текстов <br/>
<br/>
Так как все эти словари не очень большие, то я принял решение использовать их все. Оставалось дело за малым - построить готовое решение <br/>
<br/>
Изначально была сделана загрузка этих словарей + вовзращение оценки для каждого слова по ним (см. dictionaries.py) <br/>
Далее был написан SentimentalEstimator( sentimental_estimator.py ), который разбивает предложение на слова, оценивает их по всем словарям в отдельности, и возвращает результат <br/>
Результат определяется по очень простой формуле если abs( pos - negative ) < neutral_treshold, то результат - нейтральный, иначе возвращаем pos или negative <br/>
<br/>
Разбиение предложения на слова происходит так: <br/>
а) Сначала мы удаляем из предложения пунктуацию и цифры <br/>
б) Затем мы разбиваем его на слова <br/>
в) И наконец приводим каждое слово в начальную форму (для существительных это - ед.ч., м.р., и.п.) <br/>

Возникла потребность в оценке полученной машины. Для этого был написан класс TextsCorpus(textscorpus.py) и вспомогательная функция (get_sentences_quality), которые прогоняли алгоритм по базе из linis-crowd и писали количество правильно классифицированных ответов <br/>
<br/>
Сразу же встал вопрос как правильно настроить веса каждого словаря и neutral_treshold. Для этого я воспользовался дифф эволюцией (её можно найти в corpus_evolution.py). Я согласен, что оценивать и настраивать машинку на корпусе длинных текстов, а не отдельных предложений задача немного другая. Впрочем, я думаю, что это всё-таки улучшит результаты. <br/>
<br/>
Ну и наконец был написан некий GUI на qt4, который даёт возможность всё это поприменять и посмотреть как оно работает <br/>
<br/>
Дальнейшее улучшение: <br/>
а) Собрать корпус предложений <br/>
б) Добавить оценку вероятности того, что каждое слово позитивное или негативное, на основе этого корпуса <br/>
в) Соединить это с текущим подходом с оценкой по словарю<br/>
г) Разные функции отнесения к тому или иному классу. Например, сначала отделять нейтральные, а затем уже делить на позитивные и негативные<br/>
